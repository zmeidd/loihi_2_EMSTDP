{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the threhold for OOD detection\n",
    "<ul>\n",
    "<li><b>Change the data path to your own data, data shape:(N,64,64,3)</b></li>\n",
    "<li><b>Change the label path to your own label, label shape:(N,)</b></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels 4\n",
      "done split data\n",
      "epoch   1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daz/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0246, Accuracy: 13088/20000 (65%)\n",
      "\n",
      "epoch   2\n",
      "\n",
      "Test set: Average loss: 0.1303, Accuracy: 19201/20000 (96%)\n",
      "\n",
      "epoch   3\n",
      "\n",
      "Test set: Average loss: 0.1164, Accuracy: 19326/20000 (97%)\n",
      "\n",
      "epoch   4\n",
      "\n",
      "Test set: Average loss: 0.0421, Accuracy: 19698/20000 (98%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0421, Accuracy: 19698/20000 (98%)\n",
      "\n",
      "Error Rate 1.51\n",
      "done in distribution testing\n",
      "out_score ood -0.8130888\n",
      "in_score ood -0.9851891\n",
      "wrong ratio 0.02365\n",
      "\t\t\t\tOurs\n",
      "FPR80:\t\t\t13.68\n",
      "AUROC: \t\t\t91.22\n",
      "AUPR:  \t\t\t71.56\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "from oe_disac import *\n",
    "#find the threshold score\n",
    "threshold_score = ood_detection(data_path = DATA_PATH,label_path =LABEL_PATH,num_trains =20000\n",
    "                  ,num_ood=10000, percentile = 0.8)\n",
    "print(threshold_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Change the saved model path in oe_disac.py if you want to save it in another place</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model and\n",
    "net = Net().cuda()\n",
    "net.load_state_dict(torch.load(SAVED_MODEL_PATH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now you can Test the OOD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dis_data = np.load(\"out_dis_data.npy\")\n",
    "out_dis_label = np.load(\"out_dis_label.npy\")\n",
    "out_dataset = loihi_set([out_dis_data,out_dis_label])\n",
    "out_loader = torch.utils.data.DataLoader(out_dataset,batch_size= 64, shuffle=False)\n",
    "out_score = get_ood_scores(net,out_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the boolean array of the detection result outlier dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "bool_arr = out_score>threshold_score\n",
    "print(bool_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the percentage of the detection result, since we are deteting the whole outlier set, the result should be good if it is close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(bool_arr.sum()/len(out_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
